# Effects of Increased Compulsory Schooling Policy on Earnings

## Introduction

Compulsory schooling mandate of Turkey has been increased from 8 to 12 years in 2012. This policy change has impacted \<some_number\> of people when enacted. At the time, the policy was challenged by many families who argued that their children would not benefit from this additional years of education. They argued that their sons are better off working at a earlier age to gain *on-the-job* *training* which would earn them more money compared to additional schooling. Similarly these families argued that their daughters should marry and start a family instead of having education. While education and earnings have a multifaceted relationship, we investigate the causal aspects of this relationship using compulsory schooling policy change as an explanatory variable.

## Literature Review

The theory behind the possible impact of compulsory education on wages is human capital theory, which suggests that individuals increase their productivity by acquiring knowledge and skills through schooling and training (Schultz, 1961; Becker, 1962; Mincer, 1974).

Research describing the relationship between compulsory schooling and individual earnings is not very extensive. However, the relationship between these variables has been studied for a long time. It is possible to mention the work of Angrist and Krueger (1991), where they use compulsory schooling laws to estimate their causal effect on earnings. Furthermore, Harmon and Walker (1995) carried out a similar study, but based on the example of the United Kingdom, and obtained positive and significant results for the implementation of compulsory schooling. Subsequently, Oreopoulos (2006) extended the research beyond the United Kingdom and added to the analysis the cases of the United States, Canada and Ireland, obtaining similar results. Also worth mentioning is the study by Pischke and Von Wachter (2008), which examines the impact of an additional year of compulsory schooling on wages in Germany. However, the results are not consistent with those obtained in the previous studies, but the authors justify this with the specificities of the German case. Finally, Fang et al. (2012) also carried out the same exercise, but in China, and obtained more encouraging results than the other studies mentioned. However, this time the authors identify the impact of other aspects, in particular the rapid economic transformation and the increased demand for educated labour in the country.

### Loading Libraries

```{r}
library(ggplot2)
library(dplyr)
library(gridExtra) 
library(tidymodels)
library(tidyverse)
library(here)
library(readr)
library(rsample)
library(haven)
library(recipes)     
library(workflows)   
library(DoubleML)
library(mlr3)
library(mlr3learners)  
library(ranger)        


```

## Data Cleaning

1.  Combine 2021 - 2022 Data sets

```{r}

# Read dta data
data_2021 <- read_dta("data/dta/data_2021.dta")
data_2022 <- read_dta("data/dta/data_2022.dta")

# Combine datasets
earnings_data <- bind_rows(data_2022, data_2021)

# Save it as RDS
saveRDS(earnings_data, "data/combined_data.rds")

```

2.  Rename our variables to English

```{r}

# first rename the variables: 
# yas -> age, medeni_durum -> marital_status, ibbs_2 -> region, cinsiyet -> gender

earnings_data <- earnings_data %>%
  rename(
    year = referans_yil,
    age = yas,                    
    marital_status = medeni_durum,
    region = ibbs_2,              
    gender = cinsiyet,
    education_level = okul_biten_k,
    monthly_income = gelir_gecenay_k,
    working_hours = esas_fiili
  )
```

## Feature Engineering

#### Encoding Categorical Variables

```{r}

# now make the marital_status, region and age categorical variables

# Transform the data with proper categorical variables
earnings_data <- earnings_data %>%
  mutate(
    # Convert marital status to a factor with descriptive levels
    marital_status = factor(marital_status,
      levels = c(1, 2, 3, 4),
      labels = c("Never married", "Married", "Divorced", "Widowed")
    ),
    
    # Convert gender to a factor 
    gender = factor(gender,
      levels = c(1, 2),
      labels = c("female", "male")
    ),
    
    # Convert region to a factor
    # Note: Using NUTS2 regional classification for Turkey
    region = factor(region,
      levels = c(
        "TR10", "TR21", "TR22", "TR31", "TR32", "TR33",
        "TR41", "TR42", "TR51", "TR52", "TR61", "TR62",
        "TR63", "TR71", "TR72", "TR81", "TR82", "TR83",
        "TR90", "TRA1", "TRA2", "TRB1", "TRB2", "TRC1",
        "TRC2", "TRC3"
      ),
      labels = c(
        "Istanbul", "Tekirdag", "Balikesir", "Izmir", "Aydin", "Manisa",
        "Bursa", "Kocaeli", "Ankara", "Konya", "Antalya", "Adana",
        "Hatay", "Kirikkale", "Kayseri", "Zonguldak", "Kastamonu",
        "Samsun", "Trabzon", "Erzurum", "Agri", "Malatya", "Van",
        "Gaziantep", "Sanliurfa", "Mardin"
      )
    ),
    
    # Create age groups in meaningful intervals
    # First create the categories, then convert to factor
    age_sq = age**2,
    age_group = cut(age,
      breaks = c(17, 25, 35, 45, 55, 65),
      labels = c("18-25", "26-35", "36-45", "46-55", "56-65"),
      include.lowest = TRUE
    )
  )

# Check the structure of our categorical variables
(
  str(earnings_data[c("marital_status", "region", "age_group", "gender")])  
)


# See the distribution of our new categorical variables
(
  summary(earnings_data[c("marital_status", "region", "age_group", "gender")])  
)

```

#### Creating Log_Hourly_Wage Outcome Variable

```{r}

# Calculate wages and clean the data of NA/infinite values
earnings_data <- earnings_data %>%
  # First calculate wages with inflation adjustment
  mutate(
    real_monthly_income = case_when(
      year == 2022 ~ monthly_income / 1.72,  # Adjust 2022 wages to 2021 prices
      year == 2021 ~ monthly_income,         # Keep 2021 wages as is
      TRUE ~ NA_real_                        # Handle any unexpected years
    ),
    
    # Calculate hourly wage
    real_hourly_wage = real_monthly_income / (working_hours * 4.3),
    
    # Calculate log of hourly wage
    log_hourly_wage = log(real_hourly_wage)
  ) %>%
  # Now remove problematic cases
  filter(
    !is.na(log_hourly_wage),     # Remove NA values
    !is.infinite(log_hourly_wage) # Remove infinite values
  )

```

2.  lets create treatment variables for compulsory schooling

```{r}

# then lets create treatment variables for individuals effected by compulsory schooling policy
earnings_data <- earnings_data %>%
  mutate(
    # Treatment1: At least middle school (8 years) vs less education
    treatment1 = case_when(
      education_level %in% c(3, 41, 42, 511, 512, 52) ~ 1,  # 8+ years of education
      education_level %in% c(1, 2) ~ 0,                     # Less than 8 years
      TRUE ~ NA_real_                                       # Other cases
    ),
    
    # Treatment2: At least high school vs less education
    treatment2 = case_when(
      education_level %in% c(41, 42, 511, 512, 52) ~ 1,     # High school or more
      education_level %in% c(1, 2, 3) ~ 0,                  # Less than high school
      TRUE ~ NA_real_
    ),
    
    # Treatment3: At least university vs less education
    treatment3 = case_when(
      education_level %in% c(511, 512, 52) ~ 1,             # University or more
      education_level %in% c(1, 2, 3, 41, 42) ~ 0,          # Less than university
      TRUE ~ NA_real_
    )
  )

earnings_data <- earnings_data %>%
  mutate(
    university_treatment = case_when(
      # University or higher education (codes 511, 512, 52)
      education_level %in% c(511, 512, 52) ~ 1,
      # Below university education
      education_level %in% c(1, 2, 3, 41, 42) ~ 0,
      TRUE ~ NA_real_
    )
  )
```

## Exploratory Data Analysis (EDA)

### Filtering NA's

1.  filter unnecessary items & NA items

```{r}

# filter intermediate variables
earnings_data <- earnings_data %>%
  select(
    year,
    age,        
    age_sq,
    age_group,
    marital_status,
    region,    
    gender,
    education_level,
    working_hours,
    monthly_income,
    log_hourly_wage,
    treatment1,
    treatment2,
    treatment3,
    university_treatment
  )

```

4.  Let's examine if the missing values are related to any particular groups in our data:

```{r}
# Check if missing values are more common in certain groups
earnings_data %>%
  group_by(gender) %>%
  summarize(
    missing_rate = mean(is.na(log_hourly_wage)),
    total_count = n()
  )

# Check by education level
earnings_data %>%
  group_by(education_level) %>%
  summarize(
    missing_rate = mean(is.na(log_hourly_wage)),
    total_count = n()
  )


# Compare key statistics before and after NA removal
compare_stats <- function(data_before, data_after) {
  # Function to calculate summary statistics
  get_stats <- function(data) {
    data %>%
      summarize(
        mean_age = mean(age, na.rm = TRUE),
        prop_male = mean(gender == "female", na.rm = TRUE),
        mean_working_hours = mean(working_hours, na.rm = TRUE)
      )
  }
  
  before_stats <- get_stats(data_before)
  after_stats <- get_stats(data_after)
  
  # Print comparison
  print("Summary statistics comparison:")
  print(bind_rows(
    before_stats %>% mutate(dataset = "Before NA removal"),
    after_stats %>% mutate(dataset = "After NA removal")
  ))
}
```

### Plots

```{r}

# distribution of log hourly wages
p1 <- ggplot(earnings_data, aes(x = log_hourly_wage)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  geom_vline(aes(xintercept = mean(log_hourly_wage, na.rm = TRUE)), 
             color = "red", linetype = "dashed") +
  labs(
    title = "Distribution of Log Hourly Wages",
    subtitle = "Red line indicates mean wage",
    x = "Log Hourly Wage",
    y = "Frequency"
  ) +
  theme_minimal()

# earnings by education level
p2 <- ggplot(earnings_data, aes(x = factor(treatment1), y = log_hourly_wage)) +
  geom_boxplot(fill = "lightblue") +
  labs(
    title = "Log Hourly Wages by Education Level",
    x = "Education Treatment (1 = 8+ years)",
    y = "Log Hourly Wage"
  ) +
  theme_minimal()

# time trends
p3 <- ggplot(earnings_data, aes(x = log_hourly_wage, fill = factor(year))) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Wage Distribution by Year",
    x = "Log Hourly Wage",
    y = "Density",
    fill = "Year"
  ) +
  theme_minimal()

# regional wage variation
p4 <- earnings_data %>%
  group_by(region) %>%
  summarise(mean_wage = mean(log_hourly_wage, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(region, mean_wage), y = mean_wage)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() +
  labs(
    title = "Average Log Hourly Wage by Region",
    x = "Region",
    y = "Mean Log Hourly Wage"
  ) +
  theme_minimal()


# Arrange plots in a grid
grid.arrange(p1, p2, p3, p4, ncol = 2)

ggsave("firsts_plots.jpg", plot = grid.arrange(p1, p2, p3, p4, ncol = 2), width = 12, height = 8, dpi = 300, units = "in")

```

## Directed Acyclic Graph (DAG)

We use DAG for plotting the associations between various co-variate and our outcome variable, earnings.

Outcome: Log hourly Earning = Y\
Explanatory Variables: Region, Gender, Age, Marital Status

```{r}

# Code for DAG showing relationships between earnings and demographic variables
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
library(tidyverse)
library(dagitty)
library(ggdag)
library(gganimate)
library(ggthemes)
theme_set(theme_gray(base_size = 15))

# Set seed for reproducibility
set.seed(123)

# Create the DAG structure
# Y: Log hourly earnings
# R: Region
# G: Gender
# A: Age
# M: Marital Status
# S: Schooling

dag <- dagify(
    # Direct effects on Log hourly earnings (Y)
    Y ~ R + G + A + M + S,
    
    # Potential relationships between explanatory variables
    S ~ R + G + A, #Schooling might be affected by region, gender and age.
    M ~ A + G,  # Marital status might be influenced by age and gender.
    G ~ R,      # Gender composition might vary by region.
    
    # Add variable labels for clarity
    labels = c(
        "Y" = "Log Hourly Earnings",
        "R" = "Region",
        "G" = "Gender",
        "A" = "Age",
        "M" = "Marital Status",
        "S" = "Schooling"
    )
) %>%
    tidy_dagitty()

# Create the visualization with improved styling
dag_plot <- ggplot(dag) +
    geom_dag_edges_link(
        aes(x = x, y = y, xend = xend, yend = yend, circular = circular),
        arrow = grid::arrow(length = unit(0.3, "cm"), type = "closed"),
        edge_alpha = 0.8
    ) +
    geom_dag_node(aes(x = x, y = y, fill = name), shape = 21, size = 18) +
    geom_dag_text(aes(x = x, y = y, label = name), color = "black", fontface = "bold", size = 7) +
    scale_fill_brewer(palette = "Blues") +                                        
    ggtitle("DAG for Earnings Analysis") +
    theme_dag_blank() +
    theme(
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
        legend.position = "none"
    )

# Display the plot
dag_plot

ggsave(
  filename = "dag.jpg",  # File name
  plot = last_plot(),            # Use the last plot created
  width = 12,                    # Width in inches
  height = 10,                   # Height in inches
  dpi = 300,                     # Resolution in dots per inch
  units = "in"                   # Units for dimensions
)

```

## Employing Machine Learning Models

In this section, we will employ 2 machine learning models: Ordinary Least Square (OLS) & Double Machine Learning (DML).

**Idea:**

1.  We will first train an OLS model to predict the earnings, measure its performance and investigate the interpretability with regards to associations highlighted in DAG
2.  Then we will employ a modern DML model that promise to be more interpretable than OLS. We will compare the performance and causal estimates compared to baseline OLS model.

### Splitting Training & Testing Data

```{r}

# Create Training/Testing data folds to be used by machine learning model

set.seed(123)      # For reproducibility
earnings_split <- initial_split(
  earnings_data, 
  prop = 0.75,     # 75% for training
  strata = log_hourly_wage  # Stratify by our outcome variable
)

# Create training and testing datasets
earnings_training <- training(earnings_split)
earnings_test <- testing(earnings_split)


```

#### Check Balanced Distribution

```{r}

# Let's create visualizations to compare the distributions
# We'll create three informative plots:

# 1. Density plot comparing log hourly wage distributions
p1 <- ggplot() +
  geom_density(data = earnings_training, 
               aes(x = log_hourly_wage, color = "Training"),
               alpha = 0.5) +
  geom_density(data = earnings_test,
               aes(x = log_hourly_wage, color = "Testing"),
               alpha = 0.5) +
  labs(title = "Distribution of Log Hourly Wages",
       subtitle = "Comparing Training and Testing Sets",
       x = "Log Hourly Wage",
       y = "Density",
       color = "Dataset") +
  theme_minimal() +
  scale_color_manual(values = c("Training" = "skyblue", "Testing" = "indianred1"))

# 2. Box plots for a different perspective
p2 <- bind_rows(
  mutate(earnings_training, Set = "Training"),
  mutate(earnings_test, Set = "Testing")
) %>%
  ggplot(aes(x = Set, y = log_hourly_wage, fill = Set)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Log Hourly Wages by Dataset",
       subtitle = "Box Plot Comparison",
       y = "Log Hourly Wage",
       x = "") +
  theme_minimal()

# Let's also create a numerical summary
summary_stats <- bind_rows(
  earnings_training %>%
    summarise(
      Dataset = "Training",
      n = n(),
      Mean = mean(log_hourly_wage),
      SD = sd(log_hourly_wage),
      Median = median(log_hourly_wage),
      Q1 = quantile(log_hourly_wage, 0.25),
      Q3 = quantile(log_hourly_wage, 0.75)
    ),
  earnings_test %>%
    summarise(
      Dataset = "Testing",
      n = n(),
      Mean = mean(log_hourly_wage),
      SD = sd(log_hourly_wage),
      Median = median(log_hourly_wage),
      Q1 = quantile(log_hourly_wage, 0.25),
      Q3 = quantile(log_hourly_wage, 0.75)
    )
)

# Print numerical summaries
print("Summary Statistics for Training and Testing Sets:")
print(summary_stats)

# Display both plots side by side
plots_balanced_dist <- gridExtra::grid.arrange(p1, p2, ncol = 2)

ggsave("balanced_dist_plots.jpg", plot = plots_balanced_dist, width = 12, height = 8, dpi = 300, units = "in")

```

### Regression Model

Now we employ a linear regression model for predicting the log hour earning of a employed individual.

```{r}

# First, let's create our model specification
# We'll use linear regression with standard OLS estimation
lm_model <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

# Next, let's create a recipe for our feature engineering
# This is where we specify how we want to prepare our variables
wage_recipe <- recipe(
  log_hourly_wage ~ 
    age + age_sq + gender + marital_status + 
    region + working_hours + treatment2,
    data = earnings_training
) %>%
  step_dummy(all_nominal_predictors()) %>%
  # Normalize everything except university_treatment
  step_normalize(all_numeric_predictors(), -treatment2) %>%
  step_zv(all_predictors())


# Create a workflow that combines our model and recipe
wage_workflow <- workflow() %>%
  add_model(lm_model) %>%
  add_recipe(wage_recipe)

# Fit the model using our training data
wage_fit <- wage_workflow %>%
  fit(data = earnings_training)

# Let's examine the model results
model_results <- wage_fit %>%
  extract_fit_engine() %>%
  summary()

# Print the model summary
print(model_results)

# Let's also look at the most important coefficients
tidy_results <- tidy(wage_fit) %>%
  arrange(desc(abs(estimate)))  # Sort by absolute value of coefficient

# Print the top 10 most influential variables
print("Top 10 most influential predictors:")
print(head(tidy_results, 10))

```

#### Performance Measurements

```{r}

# We will measure performance by employing trained model agains test data
# Make predictions on test set
wage_predictions <- predict(wage_fit, earnings_test) %>%
  bind_cols(earnings_test)

# Calculate performance metrics
model_metrics <- wage_predictions %>%
  metrics(truth = log_hourly_wage, estimate = .pred)

# Print metrics
print("Model Performance Metrics:")
print(model_metrics)

# Create a scatter plot of predicted vs actual values
plot_pred_vs_actual <- ggplot(wage_predictions, aes(x = log_hourly_wage, y = .pred)) +
  geom_point(alpha = 0.5, color = "skyblue") +
  geom_abline(color = "red", linetype = "dashed", size = 1) +
  labs(
    title = "Predicted vs Actual Log Hourly Wages",
    x = "Actual Log Hourly Wage",
    y = "Predicted Log Hourly Wage"
  ) +
  theme_minimal()

ggsave("plot_predicted_vs_actual.jpg", plot = plot_pred_vs_actual, width = 12, height = 8, dpi = 300, units = "in")

```

### Double Machine Learning Model

Now we employ a DML model for predicting the log hour earning of a employed individual.

```{r}


# Prepare data for DML
dml_data_prep <- earnings_data %>% 
  select(
    log_hourly_wage,        # Outcome variable (Y)
    treatment2,             # Treatment variable (D)
    # Control variables (X)
    age,
    age_sq,
    gender,
    marital_status,
    region,
    working_hours,
  ) %>%
  na.omit() %>%
  as.data.table()

# Create DoubleML data object
dml_obj <- double_ml_data_from_data_frame(
  df = dml_data_prep,
  y_col = "log_hourly_wage",
  d_col = "treatment2",
  x_cols = c("age", "age_sq", "gender", "marital_status", 
             "region", "working_hours")
)

# Create learners for both stages
# For predicting university attendance (classification task)
learner_class <- lrn("classif.ranger",
                     num.trees = 500,
                     min.node.size = 5,
                     importance = "permutation")

# For predicting wages (regression task)
learner_reg <- lrn("regr.ranger",
                   num.trees = 500,
                   min.node.size = 5,
                   importance = "permutation")

# Create and fit DML model
dml_plr <- DoubleMLPLR$new(
  data = dml_obj,
  ml_l = learner_reg,    # For wage equation
  ml_m = learner_class,  # For university attendance equation
  n_folds = 5,          
  score = "partialling out"
)


# Fit the model
set.seed(123)
dml_plr_fit <- dml_plr$fit()

```

#### Performance Measurements

```{r}

# Create a detailed summary table
results_summary <- data.frame(
    Estimate = dml_plr_fit$coef,
    Std_Error = dml_plr_fit$se,
    t_statistic = dml_plr_fit$t_stat,
    p_value = dml_plr_fit$pval,
    CI_lower = dml_plr_fit$coef - 1.96 * dml_plr_fit$se,
    CI_upper = dml_plr_fit$coef + 1.96 * dml_plr_fit$se
)

# Print formatted results
print(results_summary)


# Create a visualization of the results
visual_results_dml <- ggplot(results_summary, aes(x = "University Effect")) +
    geom_point(aes(y = Estimate), size = 3, color = "blue") +
    geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = 0.2) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(title = "Effect of University Education on Log Hourly Wages",
         subtitle = "Estimated using Double Machine Learning",
         y = "Estimated Effect",
         x = "") +
    theme_minimal() +
    annotate("text", x = 1, y = max(results_summary$CI_upper) + 0.1,
             label = sprintf("Estimate: %.3f\np-value: %.3e",
                           results_summary$Estimate,
                           results_summary$p_value))

ggsave("visual_results_dml.jpg", plot = visual_results_dml, width = 12, height = 8, dpi = 300, units = "in")




```

### Instrumental Variable

```{r}
# First, create our instrument based on the reform
earnings_data <- earnings_data %>%
  mutate(
    # Calculate birth year and age in 2012
    birth_year = year - age,
    age_in_2012 = 2012 - birth_year,
    
    # Create reform instrument
    # People who were 14 or younger in 2012 were affected by the reform
    reform_instrument = case_when(
      age_in_2012 <= 14 ~ 1,      # Affected by reform
      age_in_2012 > 14 ~ 0,       # Not affected
      TRUE ~ NA_real_
    )
  )

# Now let's implement 2SLS (Two-Stage Least Squares)
# First stage: Predict high school completion using the reform
first_stage <- lm(treatment2 ~ 
                  reform_instrument + 
                  age + age_sq + gender + marital_status + 
                  region + working_hours,
                  data = earnings_data)

# Generate predicted values from first stage
earnings_data$predicted_education <- predict(first_stage)

# Second stage: Use predicted education to estimate wage effects
second_stage <- lm(log_hourly_wage ~ 
                   predicted_education +
                   age + age_sq + gender + marital_status + 
                   region + working_hours,
                   data = earnings_data)

# For proper standard errors, we should use the iv_robust function
# from the estimatr package
library(estimatr)

iv_model <- iv_robust(
  log_hourly_wage ~ treatment2 + 
    age + age_sq + gender + marital_status + 
    region + working_hours | 
    reform_instrument + 
    age + age_sq + gender + marital_status + 
    region + working_hours,
  data = earnings_data
)

summary(iv_model)


```

## Conclusion

Research Question: Was “4+4+4” policy effective?

Baseline Model Linear Regression showed promising results with \~50% accuracy (RMSE) and it predicted completing highschool increased wages by 43%

Using the DAG we argued that there would be endogenous variation in our treatment variable (highschool completion, specifically gender and region

Then we used a state-of-the-art Double Machine Learning Technique for eliminating this endogenous variation.

Our DML model predicted that highschool completion increases wages by 39% - 4% less than baseline prediction.\
\
We argue that this 4% was the overestimation of baseline model coming from endogenous variation.

Hence we argue that real effect of highschool completion is 39%, statistically significant and notably large.

Hence we conclude that policy change was a effective.

## References

Angrist, J. D., & Krueger, A. B. (1991). Does Compulsory School Attendance Affect Schooling and Earnings?. *The Quarterly Journal of Economics*, *106*(4), 979--1014. <https://doi.org/10.2307/2937954>

Becker, G. S. (1962). Investment in Human Capital: A Theoretical Analysis. *Journal of Political Economy*, *70*(5, Part 2), 9--49. <https://doi.org/10.1086/258724>

Fang, H., Eggleston, K. N., Rizzo, J. A., Rozelle, S., & Zeckhauser, R. J. (2012). *The Returns to Education in China: Evidence from the 1986 Compulsory Education Law* (Working Paper No. 18189). National Bureau of Economic Research. <https://doi.org/10.3386/w18189>

Harmon, C., & Walker, I. (1995). Estimates of the Economic Return to Schooling for the United Kingdom. *The American Economic Review*, *85*(5), 1278--1286.

Mincer, J. A. (1974). The Human Capital Earnings Function. In *Schooling, Experience, and Earnings* (pp. 83--96). NBER. <https://www.nber.org/books-and-chapters/schooling-experience-and-earnings/human-capital-earnings-function>

Oreopoulos, P. (2006). Estimating Average and Local Average Treatment Effects of Education when Compulsory Schooling Laws Really Matter. *American Economic Review*, *96*(1), 152--175. <https://doi.org/10.1257/000282806776157641>

Pischke, J.-S., & von Wachter, T. (2008). Zero Returns to Compulsory Schooling in Germany: Evidence and Interpretation. *The Review of Economics and Statistics*, *90*(3), 592--598. <https://doi.org/10.1162/rest.90.3.592>

Schultz, T. W. (1961). Investment in Human Capital. *The American Economic Review*, *51*(1), 1--17.
